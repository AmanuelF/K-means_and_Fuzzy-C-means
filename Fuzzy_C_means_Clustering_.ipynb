{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.1"
    },
    "colab": {
      "name": "Fuzzy C-means Clustering - CS 7830.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTcUjfx5KleR"
      },
      "source": [
        "\n",
        "# Fuzzy C-means Clustering\n",
        "\n",
        "## This program performs Fuzzy C-means clustering on the Flu dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gqz3Z0CHIqbP"
      },
      "source": [
        "### Mount Google Drive if working on google colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFXKOedVTEf3",
        "outputId": "cf8f09f1-bb25-4537-9c91-6860cba7ed98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2_TPfDneixB"
      },
      "source": [
        "## Change directory to a path where data is located with respect to the code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdTzSxJ_TFwW",
        "outputId": "1f61445c-aaf1-48f5-d144-cf9f94549940",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/drive/My\\ Drive/clustering"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Courses/Machine Learning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsCQvadLpidL"
      },
      "source": [
        "### Install packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnR4CmxYUumI",
        "outputId": "1e36405e-0298-41b8-cc02-6e6922bf84cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "!pip3 install numpy\n",
        "!pip3 install pandas\n",
        "!pip3 install scikit-learn\n",
        "!pip3 install seaborn\n",
        "!pip3 install matplotlib\n",
        "!pip3 install scipy\n",
        "!pip3 install statistics"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.0.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas) (1.15.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.18.5)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (0.10.1)\n",
            "Requirement already satisfied: matplotlib>=2.1.2 in /usr/local/lib/python3.6/dist-packages (from seaborn) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.18.5)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.0.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->seaborn) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->seaborn) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->seaborn) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->seaborn) (2.4.7)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22.0->seaborn) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib>=2.1.2->seaborn) (1.15.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.18.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.18.5)\n",
            "Collecting statistics\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/3a/ae99a15e65636559d936dd2159d75af1619491e8cb770859fbc8aa62cef6/statistics-1.0.3.5.tar.gz\n",
            "Requirement already satisfied: docutils>=0.3 in /usr/local/lib/python3.6/dist-packages (from statistics) (0.15.2)\n",
            "Building wheels for collected packages: statistics\n",
            "  Building wheel for statistics (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for statistics: filename=statistics-1.0.3.5-cp36-none-any.whl size=7454 sha256=900cfb51339441dd56efc957086f3117aa16518fbc5c4b094c567a23d51a3008\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/55/90/73aa7662bfb4565b567618547a275f01372a678ca92ecd64f3\n",
            "Successfully built statistics\n",
            "Installing collected packages: statistics\n",
            "Successfully installed statistics-1.0.3.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neD3OAh6KleT"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfOcXMQgKleW"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "from pprint import pprint\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from collections import defaultdict\n",
        "from scipy.spatial import distance\n",
        "import statistics\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2p9NM3vw5pyN"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAy9cBdNU5zW"
      },
      "source": [
        "## Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQjITf3w44Fw"
      },
      "source": [
        "df = pd.read_csv('Assignment-I/Assignment1_data.csv')   # change to the path where the data is stored"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysXhguCsUGQ9",
        "outputId": "8c13d383-51cb-4915-b16a-0b6542add728",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "df.replace([np.inf, -np.inf], np.nan)\n",
        "df = df.dropna()\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Student</th>\n",
              "      <th>Vaccin</th>\n",
              "      <th>HndWshQual</th>\n",
              "      <th>HndWshFreq</th>\n",
              "      <th>SociDist</th>\n",
              "      <th>NoFaceContact</th>\n",
              "      <th>RespEttiqu</th>\n",
              "      <th>PersnDist</th>\n",
              "      <th>HandSanit</th>\n",
              "      <th>Risk</th>\n",
              "      <th>Complications</th>\n",
              "      <th>Barriers</th>\n",
              "      <th>Inefficacy</th>\n",
              "      <th>KnowlTrans</th>\n",
              "      <th>KnowlMgmt</th>\n",
              "      <th>Sick</th>\n",
              "      <th>Flu</th>\n",
              "      <th>Female</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.770</td>\n",
              "      <td>-1.453</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.929</td>\n",
              "      <td>-0.554</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.345</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.489</td>\n",
              "      <td>0.149</td>\n",
              "      <td>-0.554</td>\n",
              "      <td>1.482</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.406</td>\n",
              "      <td>-0.575</td>\n",
              "      <td>-0.234</td>\n",
              "      <td>0.693</td>\n",
              "      <td>-0.182</td>\n",
              "      <td>-1.482</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.770</td>\n",
              "      <td>0.097</td>\n",
              "      <td>0.546</td>\n",
              "      <td>0.554</td>\n",
              "      <td>0.684</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.169</td>\n",
              "      <td>-0.169</td>\n",
              "      <td>-0.726</td>\n",
              "      <td>0.370</td>\n",
              "      <td>0.951</td>\n",
              "      <td>0.684</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Student  Vaccin  HndWshQual  HndWshFreq  ...  KnowlMgmt  Sick  Flu  Female\n",
              "0        1       3           4           4  ...      0.000   0.0  0.0     1.0\n",
              "1        2       2           4           4  ...      1.482   1.0  0.0     0.0\n",
              "2        3       3           2           2  ...     -1.482   0.0  0.0     0.0\n",
              "4        5       2           5           3  ...      0.684   1.0  0.0     0.0\n",
              "5        6       2           5           5  ...      0.684   2.0  1.0     0.0\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMlakTLXgSNg"
      },
      "source": [
        "### Fuzzy C-means clustering implementation block. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2gVzr0Aat6B"
      },
      "source": [
        "# Function to extract features along with the data points\n",
        "# the function accepts list of features and returns data with only these features\n",
        "def _extractFeatures(features):\n",
        "  return df[features].dropna()\n",
        "\n",
        "# Method to compute dunn index when passed records (with their cluster label) and centroids (with their cluster labels)\n",
        "def _computeDunnIndex(records, centroids):\n",
        "  # Compute inter cluster distances----i.e., distances between the centroids\n",
        "  list_centroids = list(centroids.values())\n",
        "  smallest_inter_cluster_dist = 1000000  # Assuming smallest inter-cluster distance can't be over 100000\n",
        "  for idx, current_cent in enumerate(list_centroids):\n",
        "    for next_cent in list_centroids[idx+1:]:\n",
        "      dist = distance.euclidean(current_cent, next_cent)\n",
        "      if dist < smallest_inter_cluster_dist:\n",
        "        smallest_inter_cluster_dist = dist\n",
        "\n",
        "  # Computer intra-cluster distances\n",
        "  # Iterate through the records\n",
        "  largest_intra_cluster_dist = 0.0\n",
        "  for cluster_label, points in records.items():\n",
        "    for point in points:\n",
        "      dist = distance.euclidean(point,centroids[cluster_label])\n",
        "      if dist > largest_intra_cluster_dist:\n",
        "        largest_intra_cluster_dist = dist\n",
        "\n",
        "  dunn_idx = float(smallest_inter_cluster_dist)/largest_intra_cluster_dist\n",
        "  return dunn_idx\n",
        "\n",
        "# Method to compute the sum of squared errors given cluster_dict {cluster-0: (rec-0, w-0), cluster-1: (rec-1, w-1),..., cluster-(k-1): (rec-k-1, w-(k-1))}\n",
        "# and centroid_dict {cluster-0: centroid-0, cluster-1: centroid-1,..., cluster-k-1: centroid-2}\n",
        "\n",
        "class FuzzyCMeans:\n",
        "  def __init__(self, k, p, data, eps):\n",
        "    self.k = k   # number of clusters\n",
        "    self.p = p   # fuzzification parameter\n",
        "    self.data = data  # data to cluster\n",
        "    self.eps = eps     # threshold to detect if centroids significantly changed position \n",
        "  \n",
        "  # Method to perform Fuzzy C means clustering---accepts number of clusters, p, the data with specific features, and convergence parameter\n",
        "  def _fuzzyCMeansSSE(self, cluster_dict, centroid_dict):\n",
        "    sum_over_clusters = 0.0\n",
        "    for cluster_id, records_w_weights in cluster_dict.items():\n",
        "      sum_over_records = 0.0\n",
        "      for rec_weight in records_w_weights:   # rec_weight is a tuple of record-weight\n",
        "        record = rec_weight[0]\n",
        "        weight = rec_weight[1]\n",
        "        centroid = centroid_dict[cluster_id]\n",
        "        sum_over_records += math.pow(weight, self.p) * distance.euclidean(record, centroid)\n",
        "      sum_over_clusters += sum_over_records\n",
        "    \n",
        "    return sum_over_clusters\n",
        "  \n",
        "  def _fuzzyCMeans(self):\n",
        "    # standardize the data\n",
        "    data_std = StandardScaler().fit_transform(self.data)\n",
        "    # randomly initialize w_ij(weight of record i in cluster j) as many as there are number of clusters (i.e., 'k')\n",
        "    record_dict = defaultdict(list)    # the key is the data point identifier--row index and the value is the list of weights in each cluster (there are 'k' clusters)\n",
        "    \n",
        "    for record_idx, record in enumerate(data_std):\n",
        "      weight_list = np.random.random(self.k)\n",
        "      weight_list /= weight_list.sum()    # to make sure all weights of a record sum to 1\n",
        "\n",
        "      # record_dict holds the record associated with the weight_list of the record in a dictionary as a tuple\n",
        "      record_dict[record_idx] = (record, weight_list)  # all the elements of the list, whose length is equal to the number of clusters, sum upto 1---each index in the list corresponds to cluster label\n",
        "    \n",
        "    cluster_dict = defaultdict(list) # key is the cluster label and value is tuples of record-weight\n",
        "    # assign all points to the respective clusters\n",
        "    for record_idx, record_w_weights in record_dict.items():\n",
        "      record = record_w_weights[0]   # the first element of the dict is the record\n",
        "      \n",
        "      # iterate through the weight list to grab the weight corresponding to the different clusters\n",
        "      for cluster_id, weight in enumerate(record_w_weights[1]): \n",
        "        # record stays the same in the different clusters---only the weight changes\n",
        "        cluster_dict[cluster_id].append((record, weight))  # weights across different data points having the same index location in their weight_list are put to the same cluster\n",
        "    \n",
        "    minimal_centroid_change = 0  # keeps track of how many centroids havent' significantly changed\n",
        "    centroid_dict = {}\n",
        "    # initialize centroids to the first points from cluster_dict\n",
        "    for idx, records_w_weights in cluster_dict.items():\n",
        "      centroid_dict[idx] = records_w_weights[0][0] \n",
        "\n",
        "    while True:\n",
        "      # compute centroids---iterate over cluster_dict which has record-weight mappings of all data points assigned to each cluster\n",
        "      numerator = np.zeros(data_std[0].shape) # the numerator has a form of one of the data points (a record)\n",
        "      denominator = 0.0\n",
        "      for cluster_id, records_w_weights in cluster_dict.items():  # weight_list here is the weights of the different data points assigned to a cluster\n",
        "        for record_weight in records_w_weights:\n",
        "          record, weight = record_weight[0], record_weight[1]   \n",
        "          # computing centroids in fuzzy c means is different from k-means\n",
        "          numerator += record * (math.pow(weight, self.p))\n",
        "          denominator += math.pow(weight, self.p)\n",
        "\n",
        "        centroid = numerator / denominator   # computing new centroid for a cluster\n",
        "\n",
        "        diff = distance.euclidean(centroid_dict[cluster_id], centroid)   # change in newly computed centroid and old centroid\n",
        "        if diff < self.eps:\n",
        "          minimal_centroid_change += 1\n",
        "\n",
        "        if minimal_centroid_change == self.k:   # if minimal_centroid_change counter hits 'k', it means all centroids \"stopped\" movind and thus all clusters have converged\n",
        "          return cluster_dict, centroid_dict   #return mapping to the calling program\n",
        "\n",
        "        centroid_dict[cluster_id] = centroid   # cluster_id to centroid mapping\n",
        "\n",
        "      # Recompute w_ij for each data point in each cluster\n",
        "      for cluster_id, records_w_weights in cluster_dict.items():\n",
        "        centroid = centroid_dict[cluster_id]   # centroid in the current cluster\n",
        "        \n",
        "        for record_weight in records_w_weights:\n",
        "          record = record_weight[0]   # the first item in the tuple is the record\n",
        "\n",
        "          record_current_centroid_dist = distance.euclidean(record, centroid)   # numerator of the denominator---distance from current centroid(in the current cluster)\n",
        "          ratio_raised = 0.0  # a value corresponding to a record in a cluster----i.e., with each record, ratio_raised is reset\n",
        "          # iterate through each cluster and compute distance of the record from the other centroids\n",
        "          for cluster_id in range(self.k):\n",
        "            all_centroid = centroid_dict[cluster_id]\n",
        "            record_all_centroid_dist = distance.euclidean(record, all_centroid)\n",
        "            ratio = float(record_current_centroid_dist) / record_all_centroid_dist\n",
        "            \n",
        "            ratio_raised += math.pow(ratio, 2/(self.p - 1))    # entire denominator in w_ij computation\n",
        "\n",
        "          weight_updated = 1 / float(ratio_raised)  # This value is then placed along with the record in the relevant dictionaries\n",
        "          for idx, rec_weight in enumerate(cluster_dict[cluster_id]):\n",
        "            if (rec_weight[0] == record).all():\n",
        "              cluster_dict[cluster_id][idx] = (record, weight_updated)\n",
        "\n",
        "      # Normalizing the weights of the records by first indexing the weights using their record ids\n",
        "      record_w_weights_list = defaultdict(list)  # key is record identifier and value is list of weights for the record\n",
        "      for cluster_id, list_records_w_weights in cluster_dict.items():\n",
        "        for record_idx, record_weight in enumerate(list_records_w_weights):\n",
        "          record_w_weights_list[record_idx].append(float(record_weight[1]))\n",
        "          \n",
        "      # Next normalize these weights that are mapped to their respective records\n",
        "      # we will then have {rec-1:[normalized_weight-1, normalized_weight-2,...], rec-2:[......]}\n",
        "      for record_idx, list_weights in record_w_weights_list.items():\n",
        "        record_w_weights_list[record_idx] = [weight/sum(list_weights) for weight in list_weights]\n",
        "  \n",
        "      # update cluster_dict accordingly(i.e., change the weight of each record in each cluster)\n",
        "      for record_idx, list_weights in record_w_weights_list.items():\n",
        "        for cluster_id, weight in enumerate(list_weights):\n",
        "          cluster_dict[cluster_id][record_idx] = (cluster_dict[cluster_id][record_idx][0], weight)\n",
        "\n",
        "  # Method that returns records and their weights in different clusters when pass the cluster dictionary returned by the \n",
        "  # main fuzzy c-means clustering method above\n",
        "  def _getRecordAndWeights(self, cluster_dict):\n",
        "    # Extract the records along with their cluster membership and their weights\n",
        "    record_dict = defaultdict(list)    # this data structure will have the form {cluster_id:[record-1, record-2,..., record-m]}\n",
        "    for cluster_id, records_w_weights in cluster_dict.items():\n",
        "      for record_w_weight in records_w_weights:\n",
        "        record_dict[cluster_id].append(record_w_weight[1])\n",
        "    return record_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9WYpObThBNe"
      },
      "source": [
        "### Select features that gave the best combination in K-means clustering when evaluated on Dunn Index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObhxzV4HeI0P"
      },
      "source": [
        "# Features to extract\n",
        "features = ['Risk', 'NoFaceContact', 'Sick', 'HandSanit', 'HndWshQual']   # From K-means clustering task\n",
        "\n",
        "df_cluster = _extractFeatures(features)  # the data to cluster"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQkK3_3Fkf57"
      },
      "source": [
        "### Run Fuzzy C-means clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVvx3d_fq5wZ"
      },
      "source": [
        "F1 = FuzzyCMeans(2, 2, df_cluster, 0.0005)   # Setting number of clusters to 2 and fuzzification parameter to 2\n",
        "cluster_dict, centroid_dict = F1._fuzzyCMeans()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDoIfu8-nEb4"
      },
      "source": [
        "### Print the centroids"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xN5mQyn_nDkq",
        "outputId": "5930e934-6e90-4d09-9c44-8d884ab5acd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "cent_0, cent_1 = centroid_dict[0], centroid_dict[1]\n",
        "\n",
        "print(cent_0)\n",
        "print(cent_1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.00942912  0.01140455  0.00255248 -0.0052038   0.00466738]\n",
            "[ 0.00184234 -0.00346128 -0.00413737  0.00408361  0.00035235]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piTCzf3bkjri"
      },
      "source": [
        "### Extract the records along with their cluster membership and their weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVq_l9hske8s"
      },
      "source": [
        "# Extract the records along with their cluster membership and their weights\n",
        "record_dict = F1._getRecordAndWeights(cluster_dict)    # this data structure will have the form {cluster_id:[record-1, record-2,..., record-m]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FqWKK9Sk0gB"
      },
      "source": [
        "### A sample record along with its weight in each of the clusters computed using the membership function after Fuzzy C-means has run and converged. Look that for a record its weights in different clusters are expected to roughly sum to 1.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAzLl_on8GID",
        "outputId": "fd8ab369-19dc-4fbb-c243-99877681d601",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sse = F1._fuzzyCMeansSSE(cluster_dict, centroid_dict)\n",
        "print(sse)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "372.1778233527125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIITZxMqvuNP"
      },
      "source": [
        "record_dict = F1._getRecordAndWeights(cluster_dict)    # {cluster_id:[record-1, record-2,..., record-m]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUNEIBvTlQRy"
      },
      "source": [
        "### A sample record along with its weight in each of the clusters computed using the membership function after Fuzzy C-means has run and converged. Look that for a record its weights in different clusters are expected to roughly sum to 1.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHeCU8UkyRkt",
        "outputId": "a4dca5cc-80ab-4d97-acc6-e786286e48f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(record_dict[0][4])\n",
        "print(record_dict[1][4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5011452594676159\n",
            "0.498854740532384\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oq1Il_pHu65L",
        "outputId": "fdcd3a04-5f9d-452a-b6cf-b12400fc29a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(_computeDunnIndex(record_dict, centroid_dict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.010004843852793125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsVB0-Ow0Ksw"
      },
      "source": [
        "### Testing Fuzzy C-means clustering with an additional feature (Problem 3c)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyP7QksNB01Y"
      },
      "source": [
        "# Select an additional feature from the data except from the 5 features in the previous tasks\n",
        "df_additional = df.drop(features, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xE3gDM1G1EVf",
        "outputId": "221dfc7e-3ecf-4647-a470-33439b372ba8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_additional.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Student</th>\n",
              "      <th>Vaccin</th>\n",
              "      <th>HndWshFreq</th>\n",
              "      <th>SociDist</th>\n",
              "      <th>RespEttiqu</th>\n",
              "      <th>PersnDist</th>\n",
              "      <th>Complications</th>\n",
              "      <th>Barriers</th>\n",
              "      <th>Inefficacy</th>\n",
              "      <th>KnowlTrans</th>\n",
              "      <th>KnowlMgmt</th>\n",
              "      <th>Flu</th>\n",
              "      <th>Female</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.453</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.929</td>\n",
              "      <td>-0.554</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.489</td>\n",
              "      <td>0.149</td>\n",
              "      <td>-0.554</td>\n",
              "      <td>1.482</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.575</td>\n",
              "      <td>-0.234</td>\n",
              "      <td>0.693</td>\n",
              "      <td>-0.182</td>\n",
              "      <td>-1.482</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.770</td>\n",
              "      <td>0.097</td>\n",
              "      <td>0.546</td>\n",
              "      <td>0.554</td>\n",
              "      <td>0.684</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.169</td>\n",
              "      <td>-0.726</td>\n",
              "      <td>0.370</td>\n",
              "      <td>0.951</td>\n",
              "      <td>0.684</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Student  Vaccin  HndWshFreq  SociDist  ...  KnowlTrans  KnowlMgmt  Flu  Female\n",
              "0        1       3           4         2  ...      -0.554      0.000  0.0     1.0\n",
              "1        2       2           4         5  ...      -0.554      1.482  0.0     0.0\n",
              "2        3       3           2         2  ...      -0.182     -1.482  0.0     0.0\n",
              "4        5       2           3         3  ...       0.554      0.684  0.0     0.0\n",
              "5        6       2           5         3  ...       0.951      0.684  1.0     0.0\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vFLzgh_2aww"
      },
      "source": [
        "### Generate a cumulative pearson's correlation score for each additional feature against the original 5 features ('Risk', 'NoFaceContact', 'Sick', 'HandSanit', 'HndWshQual'). Also remove columns 'Student', 'Flu', and 'Female'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fk3Jj0-4R1C",
        "outputId": "70c5b9be-0b66-42a5-9ae8-337a71aea753",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_additional = df_additional.drop(['Student', 'Flu', 'Female'], axis=1)\n",
        "df_additional = df_additional.dropna()\n",
        "df_additional.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Vaccin</th>\n",
              "      <th>HndWshFreq</th>\n",
              "      <th>SociDist</th>\n",
              "      <th>RespEttiqu</th>\n",
              "      <th>PersnDist</th>\n",
              "      <th>Complications</th>\n",
              "      <th>Barriers</th>\n",
              "      <th>Inefficacy</th>\n",
              "      <th>KnowlTrans</th>\n",
              "      <th>KnowlMgmt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.453</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.929</td>\n",
              "      <td>-0.554</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.489</td>\n",
              "      <td>0.149</td>\n",
              "      <td>-0.554</td>\n",
              "      <td>1.482</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.575</td>\n",
              "      <td>-0.234</td>\n",
              "      <td>0.693</td>\n",
              "      <td>-0.182</td>\n",
              "      <td>-1.482</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.770</td>\n",
              "      <td>0.097</td>\n",
              "      <td>0.546</td>\n",
              "      <td>0.554</td>\n",
              "      <td>0.684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.169</td>\n",
              "      <td>-0.726</td>\n",
              "      <td>0.370</td>\n",
              "      <td>0.951</td>\n",
              "      <td>0.684</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Vaccin  HndWshFreq  SociDist  ...  Inefficacy  KnowlTrans  KnowlMgmt\n",
              "0       3           4         2  ...       0.929      -0.554      0.000\n",
              "1       2           4         5  ...       0.149      -0.554      1.482\n",
              "2       3           2         2  ...       0.693      -0.182     -1.482\n",
              "4       2           3         3  ...       0.546       0.554      0.684\n",
              "5       2           5         3  ...       0.370       0.951      0.684\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KM7JbvdF4fgN"
      },
      "source": [
        "### Perform cumulative perason correlation for the to-be-selected features with the original features by summing the individual pearson's correlation scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzwlJTMr2vHq"
      },
      "source": [
        "from scipy.stats import pearsonr\n",
        "\n",
        "# Compute cumulative pearson correlation coefficient for each of the additinal features to determine which one is least correlated\n",
        "# with the already selected features---cumulative pearson for an additional feature is computed as the pearson against\n",
        "# all the selected features and their sum\n",
        "\n",
        "def computeCumulativePearson(originalFeatures, additionalFeatures):\n",
        "  pearson_cumulative = {}\n",
        "  for column in additionalFeatures:\n",
        "    sum_pearson = 0.0\n",
        "    for original_feature in originalFeatures:\n",
        "      corr, _ = pearsonr(df[column], df[original_feature])\n",
        "      sum_pearson += corr\n",
        "    pearson_cumulative[column] = sum_pearson\n",
        "\n",
        "  print(pearson_cumulative)\n",
        "  return pearson_cumulative"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYjznCtz9b14",
        "outputId": "ba70705c-9767-4c5e-f067-96321b62687c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "originalFeatures = ['Risk', 'NoFaceContact', 'Sick', 'HandSanit', 'HndWshQual']\n",
        "additionalFeatures = list(df_additional.columns)\n",
        "\n",
        "pearson_cumulative = computeCumulativePearson(originalFeatures, additionalFeatures)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Vaccin': 0.1435758183202581, 'HndWshFreq': 0.5378926251165679, 'SociDist': 0.4345271810521063, 'RespEttiqu': 0.030453488240095333, 'PersnDist': 0.5255863945245257, 'Complications': 0.39507329536695224, 'Barriers': -0.11403416001302383, 'Inefficacy': -0.3764013827291236, 'KnowlTrans': -0.19234972280409235, 'KnowlMgmt': -0.12491632635484362}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsF1XsmM9Rjo"
      },
      "source": [
        "### Determine the least correlated feature in pearson "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvztZChQ8EuW",
        "outputId": "c6b0777e-0382-4c29-b8fa-76fc9318be09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "target = 0\n",
        "min_corr_feature, value = min(pearson_cumulative.items(), key=lambda kv : abs(kv[1] - target))\n",
        "\n",
        "print(min_corr_feature)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RespEttiqu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ia_F_KI36iPw"
      },
      "source": [
        "### Thus, we use feature 'RespEttiqu' as an additional feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErNT0COg13bI"
      },
      "source": [
        "# Features to extract\n",
        "new_features = ['Risk', 'NoFaceContact', 'Sick', 'HandSanit', 'HndWshQual', min_corr_feature]   # change with the required features\n",
        "\n",
        "df_new = _extractFeatures(new_features)  # the raw data to perform fuzzy c-means clustering on before standardizing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbrL-mKl9rF-"
      },
      "source": [
        "### Run the fuzzy c-means clustering for the newly formed dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFOPdhcn6zLs"
      },
      "source": [
        "F2 = FuzzyCMeans(2, 2, df_cluster, 0.0005)   # Setting number of clusters to 2 and fuzzification parameter to 2\n",
        "cluster_dict_new, centroid_dict_new = F1._fuzzyCMeans()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ty0aFrOQ-z71"
      },
      "source": [
        "# Extract the records along with their cluster membership and their weights\n",
        "record_dict_new = F2._getRecordAndWeights(cluster_dict_new)    # this data structure will have the form {cluster_id:[record-1, record-2,..., record-m]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJJuszWz_44S",
        "outputId": "2934058f-bb82-4b3d-d932-0a04750f9728",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(record_dict_new[0][4])\n",
        "print(record_dict_new[1][4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4977385226892457\n",
            "0.5022614773107543\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WbWlI6f-lKf",
        "outputId": "5eced39a-00fd-436e-a5a0-c19e4562624f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sse = F2._fuzzyCMeansSSE(cluster_dict_new, centroid_dict_new)\n",
        "print(sse)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "370.94848794231234\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nphes8wzAEc6",
        "outputId": "c597fc21-0fcc-420e-ba6e-a92653625be7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(_computeDunnIndex(record_dict_new, centroid_dict_new))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.010983756709198421\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtONyB46AMJG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
